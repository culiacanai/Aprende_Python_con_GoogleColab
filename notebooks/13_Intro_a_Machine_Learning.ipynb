{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef2368b",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/culiacanai/Aprende_Python_con_GoogleColab/blob/main/notebooks/13_Intro_a_Machine_Learning.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# ü§ñ Intro a Machine Learning\n",
    "\n",
    "### Aprende Python con Google Colab ‚Äî por [Culiacan.AI](https://culiacan.ai)\n",
    "\n",
    "**Nivel:** üî¥ Avanzado  \n",
    "**Duraci√≥n estimada:** 90 minutos  \n",
    "**Requisitos:** Haber completado los Notebooks [11 NumPy](11_Intro_a_NumPy.ipynb) y [12 An√°lisis de Datos Real](12_Analisis_de_Datos_Real.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "En este notebook vas a:\n",
    "- Entender qu√© es Machine Learning y los tipos que existen\n",
    "- Conocer Scikit-learn, la librer√≠a #1 de ML en Python\n",
    "- Entrenar tu primer modelo de regresi√≥n lineal\n",
    "- Entrenar tu primer modelo de clasificaci√≥n\n",
    "- Evaluar modelos con m√©tricas reales\n",
    "- Entender el flujo completo: datos ‚Üí entrenamiento ‚Üí evaluaci√≥n ‚Üí predicci√≥n\n",
    "\n",
    "> üí° **Machine Learning** es darle a una computadora la capacidad de aprender patrones a partir de datos, sin programar reglas expl√≠citas. Es la base de la Inteligencia Artificial moderna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e82eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0. Preparaci√≥n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "# Scikit-learn (ya viene instalado en Colab)\n",
    "import sklearn\n",
    "print(f\"‚úÖ Scikit-learn versi√≥n: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd31b30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. ¬øQu√© es Machine Learning?\n",
    "\n",
    "### Programaci√≥n tradicional vs Machine Learning\n",
    "\n",
    "```\n",
    "Programaci√≥n tradicional:\n",
    "  Datos + Reglas ‚Üí Programa ‚Üí Resultado\n",
    "\n",
    "Machine Learning:\n",
    "  Datos + Resultados ‚Üí Algoritmo ‚Üí Reglas (modelo)\n",
    "```\n",
    "\n",
    "### Tipos de Machine Learning\n",
    "\n",
    "| Tipo | Qu√© hace | Ejemplo |\n",
    "|------|----------|---------|\n",
    "| **Supervisado** | Aprende de datos etiquetados | Predecir precio de casa seg√∫n sus caracter√≠sticas |\n",
    "| **No supervisado** | Encuentra patrones sin etiquetas | Agrupar clientes similares |\n",
    "| **Refuerzo** | Aprende por prueba y error | Un robot que aprende a caminar |\n",
    "\n",
    "En este notebook nos enfocaremos en **aprendizaje supervisado**, que tiene dos grandes categor√≠as:\n",
    "\n",
    "| Categor√≠a | Variable objetivo | Ejemplo |\n",
    "|-----------|------------------|---------|\n",
    "| **Regresi√≥n** | N√∫mero continuo | Predecir ventas, precios, temperaturas |\n",
    "| **Clasificaci√≥n** | Categor√≠a | Predecir si un cliente compra o no, tipo de producto |\n",
    "\n",
    "### El flujo de Machine Learning\n",
    "\n",
    "```\n",
    "1. Obtener datos\n",
    "2. Explorar y limpiar\n",
    "3. Dividir en entrenamiento y prueba\n",
    "4. Elegir un modelo\n",
    "5. Entrenar el modelo\n",
    "6. Evaluar el modelo\n",
    "7. Hacer predicciones\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b157931",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Nuestros datos: prediciendo esperanza de vida\n",
    "\n",
    "Vamos a usar el dataset Gapminder para predecir la esperanza de vida de un pa√≠s bas√°ndonos en su PIB per c√°pita y poblaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91edcec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de Gapminder\n",
    "import plotly.express as px\n",
    "gapminder = px.data.gapminder()\n",
    "\n",
    "# Usar datos de 2007 para nuestro primer modelo\n",
    "df = gapminder[gapminder[\"year\"] == 2007].copy()\n",
    "df = df.rename(columns={\n",
    "    \"country\": \"pais\", \"continent\": \"continente\", \"year\": \"anio\",\n",
    "    \"lifeExp\": \"esperanza_vida\", \"pop\": \"poblacion\", \"gdpPercap\": \"pib_per_capita\",\n",
    "})\n",
    "\n",
    "print(f\"üìä Dataset: {len(df)} pa√≠ses en 2007\")\n",
    "print(f\"\\nColumnas: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f6778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n r√°pida\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(df[\"esperanza_vida\"], bins=20, color=\"#2E86AB\", edgecolor=\"white\")\n",
    "axes[0].set_title(\"Distribuci√≥n: Esperanza de Vida\", fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"A√±os\")\n",
    "\n",
    "axes[1].hist(np.log10(df[\"pib_per_capita\"]), bins=20, color=\"#A23B72\", edgecolor=\"white\")\n",
    "axes[1].set_title(\"Distribuci√≥n: log(PIB per c√°pita)\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"log‚ÇÅ‚ÇÄ(USD)\")\n",
    "\n",
    "axes[2].scatter(df[\"pib_per_capita\"], df[\"esperanza_vida\"], alpha=0.6, color=\"#F18F01\", edgecolors=\"white\")\n",
    "axes[2].set_title(\"PIB vs Esperanza de Vida\", fontweight=\"bold\")\n",
    "axes[2].set_xlabel(\"PIB per c√°pita (USD)\")\n",
    "axes[2].set_ylabel(\"Esperanza de vida (a√±os)\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76092a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Dividir datos: entrenamiento y prueba\n",
    "\n",
    "**¬øPor qu√© dividir?** Si evaluamos el modelo con los mismos datos que usamos para entrenarlo, no sabemos si realmente aprendi√≥ o si solo \"memoriz√≥\". Es como estudiar con el examen ya resuelto.\n",
    "\n",
    "```\n",
    "Datos totales (100%)\n",
    "‚îú‚îÄ‚îÄ Entrenamiento (80%) ‚Üí El modelo aprende de estos\n",
    "‚îî‚îÄ‚îÄ Prueba (20%) ‚Üí Evaluamos con estos (el modelo nunca los vio)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d682742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preparar datos\n",
    "# X = features (variables predictoras)\n",
    "# y = target (variable a predecir)\n",
    "\n",
    "# Usamos log del PIB porque la relaci√≥n es m√°s lineal as√≠\n",
    "df[\"log_pib\"] = np.log10(df[\"pib_per_capita\"])\n",
    "df[\"log_pop\"] = np.log10(df[\"poblacion\"])\n",
    "\n",
    "X = df[[\"log_pib\"]].values  # Una sola feature por ahora\n",
    "y = df[\"esperanza_vida\"].values\n",
    "\n",
    "# Dividir: 80% entrenamiento, 20% prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Divisi√≥n de datos:\")\n",
    "print(f\"  Total:        {len(X)} pa√≠ses\")\n",
    "print(f\"  Entrenamiento: {len(X_train)} pa√≠ses ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"  Prueba:        {len(X_test)} pa√≠ses ({len(X_test)/len(X)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb73bd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Tu primer modelo: Regresi√≥n Lineal\n",
    "\n",
    "La regresi√≥n lineal busca la mejor l√≠nea recta que explique la relaci√≥n entre las variables.\n",
    "\n",
    "$$y = mx + b$$\n",
    "\n",
    "Donde:\n",
    "- $y$ = esperanza de vida (lo que queremos predecir)\n",
    "- $x$ = log(PIB per c√°pita) (lo que usamos para predecir)\n",
    "- $m$ = pendiente (cu√°nto cambia $y$ por cada unidad de $x$)\n",
    "- $b$ = intercepto (valor de $y$ cuando $x = 0$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "modelo_lr = LinearRegression()\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# Par√°metros aprendidos\n",
    "pendiente = modelo_lr.coef_[0]\n",
    "intercepto = modelo_lr.intercept_\n",
    "\n",
    "print(f\"üìê Modelo entrenado:\")\n",
    "print(f\"  Pendiente (m): {pendiente:.2f}\")\n",
    "print(f\"  Intercepto (b): {intercepto:.2f}\")\n",
    "print(f\"\\n  F√≥rmula: esperanza_vida = {pendiente:.2f} √ó log(PIB) + ({intercepto:.2f})\")\n",
    "print(f\"\\n  Interpretaci√≥n: por cada 10x aumento en PIB per c√°pita,\")\n",
    "print(f\"  la esperanza de vida aumenta ~{pendiente:.1f} a√±os\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7810c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones\n",
    "y_pred_train = modelo_lr.predict(X_train)\n",
    "y_pred_test = modelo_lr.predict(X_test)\n",
    "\n",
    "# Visualizar\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Datos de entrenamiento\n",
    "axes[0].scatter(X_train, y_train, alpha=0.6, color=\"#2E86AB\", edgecolors=\"white\", label=\"Datos reales\")\n",
    "axes[0].plot(np.sort(X_train, axis=0), modelo_lr.predict(np.sort(X_train, axis=0)),\n",
    "             color=\"#C73E1D\", linewidth=2.5, label=\"Modelo\")\n",
    "axes[0].set_title(\"Entrenamiento\", fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"log‚ÇÅ‚ÇÄ(PIB per c√°pita)\")\n",
    "axes[0].set_ylabel(\"Esperanza de vida (a√±os)\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Datos de prueba\n",
    "axes[1].scatter(X_test, y_test, alpha=0.6, color=\"#F18F01\", edgecolors=\"white\", label=\"Datos reales\")\n",
    "axes[1].plot(np.sort(X_test, axis=0), modelo_lr.predict(np.sort(X_test, axis=0)),\n",
    "             color=\"#C73E1D\", linewidth=2.5, label=\"Modelo\")\n",
    "axes[1].set_title(\"Prueba (datos nuevos)\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"log‚ÇÅ‚ÇÄ(PIB per c√°pita)\")\n",
    "axes[1].set_ylabel(\"Esperanza de vida (a√±os)\")\n",
    "axes[1].legend()\n",
    "\n",
    "for ax in axes:\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"Regresi√≥n Lineal: PIB vs Esperanza de Vida\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f5954",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Evaluar el modelo: ¬øqu√© tan bueno es?\n",
    "\n",
    "### M√©tricas de regresi√≥n\n",
    "\n",
    "| M√©trica | Qu√© mide | Ideal |\n",
    "|---------|----------|-------|\n",
    "| **R¬≤** | % de variaci√≥n explicada por el modelo | Cercano a 1 |\n",
    "| **MAE** | Error promedio absoluto | Cercano a 0 |\n",
    "| **RMSE** | Error promedio (penaliza errores grandes) | Cercano a 0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# M√©tricas en datos de PRUEBA (lo que importa)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"üìä Evaluaci√≥n del modelo (datos de prueba):\")\n",
    "print(f\"  R¬≤ Score:  {r2:.3f}  ({r2*100:.1f}% de la variaci√≥n explicada)\")\n",
    "print(f\"  MAE:       {mae:.2f} a√±os  (error promedio)\")\n",
    "print(f\"  RMSE:      {rmse:.2f} a√±os  (error promedio penalizado)\")\n",
    "\n",
    "# Comparar train vs test\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "print(f\"\\n  R¬≤ Train:  {r2_train:.3f}\")\n",
    "print(f\"  R¬≤ Test:   {r2:.3f}\")\n",
    "if r2_train - r2 > 0.1:\n",
    "    print(\"  ‚ö†Ô∏è Posible overfitting (el modelo memoriza en vez de aprender)\")\n",
    "else:\n",
    "    print(\"  ‚úÖ El modelo generaliza bien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc43d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar errores\n",
    "errores = y_test - y_pred_test\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Predicci√≥n vs Real\n",
    "axes[0].scatter(y_test, y_pred_test, alpha=0.6, color=\"#2E86AB\", edgecolors=\"white\")\n",
    "lim = [min(y_test.min(), y_pred_test.min()) - 2, max(y_test.max(), y_pred_test.max()) + 2]\n",
    "axes[0].plot(lim, lim, \"--\", color=\"#C73E1D\", linewidth=2, label=\"Predicci√≥n perfecta\")\n",
    "axes[0].set_xlabel(\"Valor real (a√±os)\")\n",
    "axes[0].set_ylabel(\"Predicci√≥n (a√±os)\")\n",
    "axes[0].set_title(\"Predicci√≥n vs Realidad\", fontweight=\"bold\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Distribuci√≥n de errores\n",
    "axes[1].hist(errores, bins=10, color=\"#A23B72\", edgecolor=\"white\", alpha=0.8)\n",
    "axes[1].axvline(0, color=\"#C73E1D\", linestyle=\"--\", linewidth=2)\n",
    "axes[1].set_xlabel(\"Error (a√±os)\")\n",
    "axes[1].set_ylabel(\"Frecuencia\")\n",
    "axes[1].set_title(\"Distribuci√≥n de Errores\", fontweight=\"bold\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Error m√°ximo: {np.max(np.abs(errores)):.1f} a√±os\")\n",
    "print(f\"Error promedio: {np.mean(np.abs(errores)):.1f} a√±os\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f880b26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Mejorar el modelo: m√°s features\n",
    "\n",
    "Un solo feature (PIB) no captura toda la historia. Agreguemos m√°s variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos con m√°s features\n",
    "# Usaremos datos de TODOS los a√±os para tener m√°s datos de entrenamiento\n",
    "df_full = gapminder.copy()\n",
    "df_full = df_full.rename(columns={\n",
    "    \"country\": \"pais\", \"continent\": \"continente\", \"year\": \"anio\",\n",
    "    \"lifeExp\": \"esperanza_vida\", \"pop\": \"poblacion\", \"gdpPercap\": \"pib_per_capita\",\n",
    "})\n",
    "\n",
    "# Crear features\n",
    "df_full[\"log_pib\"] = np.log10(df_full[\"pib_per_capita\"])\n",
    "df_full[\"log_pop\"] = np.log10(df_full[\"poblacion\"])\n",
    "\n",
    "# One-hot encoding para continentes (convertir categor√≠as a n√∫meros)\n",
    "continentes_dummies = pd.get_dummies(df_full[\"continente\"], prefix=\"cont\", drop_first=True)\n",
    "df_full = pd.concat([df_full, continentes_dummies], axis=1)\n",
    "\n",
    "# Features\n",
    "feature_cols = [\"log_pib\", \"log_pop\", \"anio\"] + list(continentes_dummies.columns)\n",
    "X_full = df_full[feature_cols].values\n",
    "y_full = df_full[\"esperanza_vida\"].values\n",
    "\n",
    "print(f\"Features utilizados ({len(feature_cols)}):\")\n",
    "for i, col in enumerate(feature_cols):\n",
    "    print(f\"  {i+1}. {col}\")\n",
    "\n",
    "print(f\"\\nDatos totales: {len(X_full)} registros\")\n",
    "\n",
    "# Dividir\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8542ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo con m√°s features\n",
    "modelo_multi = LinearRegression()\n",
    "modelo_multi.fit(X_train_f, y_train_f)\n",
    "\n",
    "# Evaluar\n",
    "y_pred_multi = modelo_multi.predict(X_test_f)\n",
    "r2_multi = r2_score(y_test_f, y_pred_multi)\n",
    "mae_multi = mean_absolute_error(y_test_f, y_pred_multi)\n",
    "rmse_multi = np.sqrt(mean_squared_error(y_test_f, y_pred_multi))\n",
    "\n",
    "print(f\"üìä Modelo con m√∫ltiples features:\")\n",
    "print(f\"  R¬≤:   {r2_multi:.3f} (antes: {r2:.3f})\")\n",
    "print(f\"  MAE:  {mae_multi:.2f} a√±os (antes: {mae:.2f})\")\n",
    "print(f\"  RMSE: {rmse_multi:.2f} a√±os (antes: {rmse:.2f})\")\n",
    "print(f\"\\n  {'‚úÖ Mejor√≥!' if r2_multi > r2 else '‚ùå No mejor√≥'}\")\n",
    "\n",
    "# Importancia de cada feature (coeficientes)\n",
    "print(f\"\\nüìê Coeficientes del modelo:\")\n",
    "for col, coef in zip(feature_cols, modelo_multi.coef_):\n",
    "    print(f\"  {col:<25} {coef:>8.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964618da",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. M√°s all√° de la regresi√≥n lineal\n",
    "\n",
    "Scikit-learn tiene muchos modelos. Vamos a comparar varios:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53788e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Escalar features (necesario para algunos modelos)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_f)\n",
    "X_test_scaled = scaler.transform(X_test_f)\n",
    "\n",
    "# Definir modelos\n",
    "modelos = {\n",
    "    \"Regresi√≥n Lineal\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "    \"√Årbol de Decisi√≥n\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42),\n",
    "    \"KNN (K=5)\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"SVR\": SVR(kernel=\"rbf\", C=100),\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar todos\n",
    "resultados = []\n",
    "for nombre, modelo in modelos.items():\n",
    "    # Usar datos escalados para KNN y SVR\n",
    "    if nombre in [\"KNN (K=5)\", \"SVR\"]:\n",
    "        modelo.fit(X_train_scaled, y_train_f)\n",
    "        y_pred = modelo.predict(X_test_scaled)\n",
    "    else:\n",
    "        modelo.fit(X_train_f, y_train_f)\n",
    "        y_pred = modelo.predict(X_test_f)\n",
    "\n",
    "    r2 = r2_score(y_test_f, y_pred)\n",
    "    mae = mean_absolute_error(y_test_f, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_f, y_pred))\n",
    "\n",
    "    resultados.append({\n",
    "        \"Modelo\": nombre,\n",
    "        \"R¬≤\": r2,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados).sort_values(\"R¬≤\", ascending=False)\n",
    "df_resultados.index = range(1, len(df_resultados) + 1)\n",
    "print(\"üèÜ Comparativa de modelos de regresi√≥n:\")\n",
    "print(df_resultados.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparativa\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "colores = [\"#2E86AB\" if r > 0.8 else \"#F18F01\" if r > 0.7 else \"#C73E1D\"\n",
    "           for r in df_resultados[\"R¬≤\"]]\n",
    "\n",
    "bars = ax.barh(df_resultados[\"Modelo\"], df_resultados[\"R¬≤\"], color=colores, edgecolor=\"white\")\n",
    "\n",
    "for bar, r2 in zip(bars, df_resultados[\"R¬≤\"]):\n",
    "    ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
    "            f\"{r2:.3f}\", va=\"center\", fontweight=\"bold\", fontsize=10)\n",
    "\n",
    "ax.set_xlabel(\"R¬≤ Score\", fontsize=12)\n",
    "ax.set_title(\"Comparativa de Modelos de Regresi√≥n\", fontsize=14, fontweight=\"bold\")\n",
    "ax.axvline(x=0.8, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"R¬≤ = 0.80\")\n",
    "ax.legend()\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.set_xlim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mejor = df_resultados.iloc[0]\n",
    "print(f\"\\nüèÜ Mejor modelo: {mejor['Modelo']} (R¬≤ = {mejor['R¬≤']:.3f}, MAE = {mejor['MAE']:.2f} a√±os)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdabe5b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Clasificaci√≥n: predecir categor√≠as\n",
    "\n",
    "Ahora vamos a cambiar de tarea: en vez de predecir un n√∫mero (regresi√≥n), vamos a **predecir una categor√≠a** (clasificaci√≥n).\n",
    "\n",
    "**Problema:** dado el PIB per c√°pita, la poblaci√≥n y el a√±o, ¬øen qu√© continente se encuentra un pa√≠s?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f383405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Preparar datos para clasificaci√≥n\n",
    "df_clf = gapminder.copy()\n",
    "df_clf[\"log_pib\"] = np.log10(df_clf[\"gdpPercap\"])\n",
    "df_clf[\"log_pop\"] = np.log10(df_clf[\"pop\"])\n",
    "\n",
    "# Features y target\n",
    "X_clf = df_clf[[\"log_pib\", \"log_pop\", \"year\"]].values\n",
    "y_clf = df_clf[\"continent\"].values\n",
    "\n",
    "# Dividir\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
    ")\n",
    "\n",
    "print(f\"üìä Clasificaci√≥n: predecir continente\")\n",
    "print(f\"  Clases: {np.unique(y_clf)}\")\n",
    "print(f\"  Train: {len(X_train_c)}, Test: {len(X_test_c)}\")\n",
    "print(f\"\\n  Distribuci√≥n de clases (test):\")\n",
    "for cont in np.unique(y_test_c):\n",
    "    count = np.sum(y_test_c == cont)\n",
    "    print(f\"    {cont}: {count} ({count/len(y_test_c)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Random Forest para clasificaci√≥n\n",
    "modelo_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "modelo_clf.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Predecir\n",
    "y_pred_c = modelo_clf.predict(X_test_c)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test_c, y_pred_c)\n",
    "print(f\"üéØ Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "\n",
    "# Reporte detallado\n",
    "print(f\"\\nüìä Reporte de clasificaci√≥n:\")\n",
    "print(classification_report(y_test_c, y_pred_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc57f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test_c, y_pred_c)\n",
    "labels = sorted(np.unique(y_test_c))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_yticks(range(len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xlabel(\"Predicci√≥n\", fontsize=12)\n",
    "ax.set_ylabel(\"Real\", fontsize=12)\n",
    "ax.set_title(\"Matriz de Confusi√≥n\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Agregar n√∫meros\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        color = \"white\" if cm[i, j] > cm.max() / 2 else \"black\"\n",
    "        ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\",\n",
    "                fontsize=14, fontweight=\"bold\", color=color)\n",
    "\n",
    "plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretaci√≥n\n",
    "print(\"üìñ C√≥mo leer la matriz:\")\n",
    "print(\"  Filas = clase real, Columnas = clase predicha\")\n",
    "print(\"  La diagonal = predicciones correctas\")\n",
    "print(\"  Fuera de la diagonal = errores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174efbb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. ¬øQu√© features importan m√°s?\n",
    "\n",
    "Los modelos basados en √°rboles nos pueden decir qu√© variables fueron m√°s √∫tiles para hacer predicciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d97112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de features en Random Forest (regresi√≥n)\n",
    "modelo_rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "modelo_rf.fit(X_train_f, y_train_f)\n",
    "\n",
    "importancias = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importancia\": modelo_rf.feature_importances_\n",
    "}).sort_values(\"importancia\", ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.barh(importancias[\"feature\"], importancias[\"importancia\"], color=\"#2E86AB\", edgecolor=\"white\")\n",
    "ax.set_title(\"Importancia de Features (Random Forest)\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Importancia\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "for i, (_, row) in enumerate(importancias.iterrows()):\n",
    "    ax.text(row[\"importancia\"] + 0.005, i, f\"{row['importancia']:.3f}\",\n",
    "            va=\"center\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüèÜ Feature m√°s importante: {importancias.iloc[-1]['feature']} ({importancias.iloc[-1]['importancia']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd2e61",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Predicciones para M√©xico üá≤üáΩ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar el mejor modelo de regresi√≥n para predecir\n",
    "# Entrenar Gradient Boosting con todos los features\n",
    "mejor_modelo = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
    "mejor_modelo.fit(X_train_f, y_train_f)\n",
    "\n",
    "# Datos hist√≥ricos de M√©xico\n",
    "mexico = gapminder[gapminder[\"country\"] == \"Mexico\"].copy()\n",
    "mexico[\"log_pib\"] = np.log10(mexico[\"gdpPercap\"])\n",
    "mexico[\"log_pop\"] = np.log10(mexico[\"pop\"])\n",
    "\n",
    "# Crear features para M√©xico\n",
    "continentes_dummies_mx = pd.get_dummies(mexico[\"continent\"], prefix=\"cont\", drop_first=True)\n",
    "for col in [c for c in feature_cols if c.startswith(\"cont_\")]:\n",
    "    if col not in continentes_dummies_mx.columns:\n",
    "        continentes_dummies_mx[col] = 0\n",
    "\n",
    "mexico_features = pd.concat([\n",
    "    mexico[[\"log_pib\", \"log_pop\", \"year\"]].rename(columns={\"year\": \"anio\"}).reset_index(drop=True),\n",
    "    continentes_dummies_mx[sorted(continentes_dummies_mx.columns)].reset_index(drop=True)\n",
    "], axis=1)[feature_cols].values\n",
    "\n",
    "# Predicciones\n",
    "predicciones_mx = mejor_modelo.predict(mexico_features)\n",
    "\n",
    "# Comparar predicci√≥n vs realidad\n",
    "print(f\"üá≤üáΩ M√©xico ‚Äî Predicci√≥n vs Realidad\")\n",
    "print(f\"{'A√±o':>6} {'Real':>8} {'Predicci√≥n':>12} {'Error':>8}\")\n",
    "print(\"-\" * 40)\n",
    "for i, (_, row) in enumerate(mexico.iterrows()):\n",
    "    error = predicciones_mx[i] - row[\"lifeExp\"]\n",
    "    print(f\"{row['year']:>6} {row['lifeExp']:>7.1f} {predicciones_mx[i]:>11.1f} {error:>+7.1f}\")\n",
    "\n",
    "mae_mx = np.mean(np.abs(predicciones_mx - mexico[\"lifeExp\"].values))\n",
    "print(f\"\\n  Error promedio para M√©xico: {mae_mx:.2f} a√±os\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d7d9d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. üèÜ Mini Proyecto: Pipeline completo de ML\n",
    "\n",
    "Vamos a construir un pipeline profesional de principio a fin para predecir si un pa√≠s tiene esperanza de vida alta o baja:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèÜ Pipeline completo: clasificar pa√≠ses en \"Alta\" o \"Baja\" esperanza de vida\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Preparar datos\n",
    "df_pipe = gapminder.copy()\n",
    "df_pipe[\"log_pib\"] = np.log10(df_pipe[\"gdpPercap\"])\n",
    "df_pipe[\"log_pop\"] = np.log10(df_pipe[\"pop\"])\n",
    "\n",
    "# Crear target binario: esperanza de vida >= mediana global = \"Alta\"\n",
    "mediana_global = df_pipe[\"lifeExp\"].median()\n",
    "df_pipe[\"categoria_ev\"] = np.where(df_pipe[\"lifeExp\"] >= mediana_global, \"Alta\", \"Baja\")\n",
    "\n",
    "print(f\"Mediana global de esperanza de vida: {mediana_global:.1f} a√±os\")\n",
    "print(f\"Alta (>= {mediana_global:.1f}): {(df_pipe['categoria_ev'] == 'Alta').sum()}\")\n",
    "print(f\"Baja (< {mediana_global:.1f}): {(df_pipe['categoria_ev'] == 'Baja').sum()}\")\n",
    "\n",
    "# Features\n",
    "X_pipe = df_pipe[[\"log_pib\", \"log_pop\", \"year\"]].values\n",
    "y_pipe = df_pipe[\"categoria_ev\"].values\n",
    "\n",
    "# 2. Dividir\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(\n",
    "    X_pipe, y_pipe, test_size=0.2, random_state=42, stratify=y_pipe\n",
    ")\n",
    "\n",
    "# 3. Crear pipeline (escalar + modelo en un solo paso)\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"modelo\", GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)),\n",
    "])\n",
    "\n",
    "# 4. Validaci√≥n cruzada (m√°s robusto que un solo train/test split)\n",
    "scores_cv = cross_val_score(pipeline, X_train_p, y_train_p, cv=5, scoring=\"accuracy\")\n",
    "print(f\"\\nüìä Validaci√≥n cruzada (5-fold):\")\n",
    "print(f\"  Scores: {scores_cv.round(3)}\")\n",
    "print(f\"  Media: {scores_cv.mean():.3f} ¬± {scores_cv.std():.3f}\")\n",
    "\n",
    "# 5. Entrenar con todos los datos de entrenamiento\n",
    "pipeline.fit(X_train_p, y_train_p)\n",
    "y_pred_p = pipeline.predict(X_test_p)\n",
    "\n",
    "# 6. Evaluar\n",
    "print(f\"\\nüéØ Accuracy en test: {accuracy_score(y_test_p, y_pred_p):.3f}\")\n",
    "print(f\"\\n{classification_report(y_test_p, y_pred_p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e160a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Predicciones para pa√≠ses espec√≠ficos\n",
    "paises_prueba = {\n",
    "    \"Mexico\": {\"pib\": 8000, \"pop\": 130_000_000, \"year\": 2025},\n",
    "    \"Nigeria\": {\"pib\": 2000, \"pop\": 220_000_000, \"year\": 2025},\n",
    "    \"Jap√≥n\": {\"pib\": 40000, \"pop\": 125_000_000, \"year\": 2025},\n",
    "    \"Chile\": {\"pib\": 15000, \"pop\": 19_500_000, \"year\": 2025},\n",
    "}\n",
    "\n",
    "print(\"üîÆ Predicciones del modelo:\")\n",
    "print(f\"  (Mediana global: {mediana_global:.1f} a√±os)\")\n",
    "print()\n",
    "\n",
    "for pais, datos in paises_prueba.items():\n",
    "    features = np.array([[np.log10(datos[\"pib\"]), np.log10(datos[\"pop\"]), datos[\"year\"]]])\n",
    "    prediccion = pipeline.predict(features)[0]\n",
    "    proba = pipeline.predict_proba(features)[0]\n",
    "    confianza = max(proba) * 100\n",
    "\n",
    "    emoji = \"‚úÖ\" if prediccion == \"Alta\" else \"‚ö†Ô∏è\"\n",
    "    print(f\"  {emoji} {pais}: {prediccion} (confianza: {confianza:.0f}%)\")\n",
    "    print(f\"     PIB: ${datos['pib']:,}, Poblaci√≥n: {datos['pop']:,}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9f09a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî• Retos\n",
    "\n",
    "1. **Predictor de PIB:** Invierte el problema ‚Äî usa esperanza de vida, poblaci√≥n, continente y a√±o para predecir el PIB per c√°pita de un pa√≠s. Compara al menos 3 modelos diferentes.\n",
    "\n",
    "2. **Detector de continente mejorado:** Mejora el clasificador de continentes agregando m√°s features (por ejemplo, crear features como PIB/habitante √ó a√±o, o ratio poblaci√≥n/PIB). Intenta superar el accuracy del modelo base.\n",
    "\n",
    "3. **Sistema de recomendaci√≥n de pol√≠ticas:** Entrena un modelo que prediga la esperanza de vida, luego √∫salo para simular: \"Si M√©xico duplica su PIB per c√°pita, ¬øcu√°ntos a√±os de esperanza de vida ganar√≠a?\". Haz la misma simulaci√≥n para otros 5 pa√≠ses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reto 1: Predictor de PIB\n",
    "# Tu c√≥digo aqu√≠ üëá\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reto 2: Detector de continente mejorado\n",
    "# Tu c√≥digo aqu√≠ üëá\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f22de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reto 3: Sistema de recomendaci√≥n de pol√≠ticas\n",
    "# Tu c√≥digo aqu√≠ üëá\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5283f6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìã Resumen\n",
    "\n",
    "### Flujo de Machine Learning\n",
    "| Paso | C√≥digo |\n",
    "|------|--------|\n",
    "| Dividir datos | `train_test_split(X, y, test_size=0.2)` |\n",
    "| Crear modelo | `modelo = RandomForestRegressor()` |\n",
    "| Entrenar | `modelo.fit(X_train, y_train)` |\n",
    "| Predecir | `y_pred = modelo.predict(X_test)` |\n",
    "| Evaluar | `r2_score(y_test, y_pred)` |\n",
    "\n",
    "### Modelos principales\n",
    "| Modelo | Tipo | Cu√°ndo usarlo |\n",
    "|--------|------|--------------|\n",
    "| Regresi√≥n Lineal | Regresi√≥n | Relaciones lineales simples |\n",
    "| √Årbol de Decisi√≥n | Ambos | Datos no lineales, interpretabilidad |\n",
    "| Random Forest | Ambos | Buen rendimiento general |\n",
    "| Gradient Boosting | Ambos | M√°ximo rendimiento |\n",
    "| KNN | Ambos | Datos peque√±os, sin entrenamiento |\n",
    "\n",
    "### M√©tricas\n",
    "| M√©trica | Regresi√≥n | Clasificaci√≥n |\n",
    "|---------|-----------|--------------|\n",
    "| R¬≤ | ‚úÖ | |\n",
    "| MAE / RMSE | ‚úÖ | |\n",
    "| Accuracy | | ‚úÖ |\n",
    "| Precision / Recall | | ‚úÖ |\n",
    "| Matriz de confusi√≥n | | ‚úÖ |\n",
    "\n",
    "### Conceptos clave\n",
    "| Concepto | Significado |\n",
    "|----------|------------|\n",
    "| **Overfitting** | El modelo memoriza en vez de aprender |\n",
    "| **Train/Test split** | Separar datos para evaluar honestamente |\n",
    "| **Cross-validation** | Evaluar con m√∫ltiples divisiones |\n",
    "| **Feature engineering** | Crear mejores variables para el modelo |\n",
    "| **Pipeline** | Encadenar pasos de preprocesamiento + modelo |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è≠Ô∏è ¬øQu√© sigue?\n",
    "\n",
    "En el siguiente notebook exploraremos **Proyecto Final con IA** ‚Äî donde aplicar√°s todo lo aprendido en un proyecto completo de principio a fin.\n",
    "\n",
    "üëâ [14 ‚Äî Proyecto Final con IA](14_Proyecto_Final_con_IA.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "<p align=\"center\">\n",
    "  Hecho con ‚ù§Ô∏è por <a href=\"https://culiacan.ai\">Culiacan.AI</a> ‚Äî Culiac√°n reconocida en el mundo por su talento y emprendimiento en Inteligencia Artificial\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
