{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1a2229",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/culiacanai/Aprende_Python_con_GoogleColab/blob/main/notebooks/14_Proyecto_Final_con_IA.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# ğŸš€ Proyecto Final con IA\n",
    "\n",
    "### Aprende Python con Google Colab â€” por [Culiacan.AI](https://culiacan.ai)\n",
    "\n",
    "**Nivel:** ğŸ”´ Avanzado  \n",
    "**DuraciÃ³n estimada:** 120 minutos  \n",
    "**Requisitos:** Haber completado los Notebooks 01â€“13\n",
    "\n",
    "---\n",
    "\n",
    "En este notebook vas a:\n",
    "- Construir un proyecto real de principio a fin que combina **APIs + datos + ML + visualizaciÃ³n**\n",
    "- Consumir APIs reales: OpenAI (GPT), Open-Meteo, ExchangeRate, RestCountries\n",
    "- Crear un **Asistente de Inteligencia de Negocios** que analiza datos y genera reportes\n",
    "- Aprender a integrar modelos de lenguaje (LLMs) en tus aplicaciones Python\n",
    "- Aplicar todo lo aprendido en el curso en un solo proyecto\n",
    "\n",
    "> ğŸ’¡ Este es el notebook que junta todo. Vas a construir algo que podrÃ­as usar en tu trabajo real.\n",
    "\n",
    "---\n",
    "\n",
    "## El Proyecto: Asistente de Inteligencia de Negocios\n",
    "\n",
    "Vamos a construir un sistema que:\n",
    "1. **Recopila datos** de mÃºltiples APIs en tiempo real\n",
    "2. **Analiza** los datos con Pandas y NumPy\n",
    "3. **Predice** tendencias con Machine Learning\n",
    "4. **Genera reportes** con texto inteligente usando la API de OpenAI\n",
    "5. **Visualiza** todo en un dashboard profesional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540bfd8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0. PreparaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dfab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai -q\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"âœ… LibrerÃ­as listas\")\n",
    "print(f\"   Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6bbf86",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Configurar las APIs\n",
    "\n",
    "Vamos a usar 4 APIs reales:\n",
    "\n",
    "| API | QuÃ© nos da | API Key |\n",
    "|-----|-----------|---------|\n",
    "| **Open-Meteo** | Clima en tiempo real y pronÃ³stico | No requiere âœ… |\n",
    "| **ExchangeRate** | Tipo de cambio actualizado | No requiere âœ… |\n",
    "| **RestCountries** | Datos de paÃ­ses | No requiere âœ… |\n",
    "| **OpenAI** | GeneraciÃ³n de texto con GPT | SÃ­ requiere ğŸ”‘ |\n",
    "\n",
    "### Configurar la API Key de OpenAI\n",
    "\n",
    "Para la secciÃ³n de OpenAI necesitas una API key. Si no la tienes:\n",
    "1. Crea una cuenta en [platform.openai.com](https://platform.openai.com/)\n",
    "2. Ve a API Keys y genera una nueva\n",
    "3. AgrÃ©gala como Secret en Colab (menÃº ğŸ”‘ a la izquierda) con el nombre `OPENAI_API_KEY`\n",
    "\n",
    "> âš ï¸ Las secciones sin OpenAI funcionan al 100% sin API key. La secciÃ³n de OpenAI es opcional pero muy valiosa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e445b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentar cargar la API key de OpenAI (opcional)\n",
    "openai_disponible = False\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
    "    openai_disponible = True\n",
    "    print(\"âœ… OpenAI API key cargada desde Colab Secrets\")\n",
    "except:\n",
    "    try:\n",
    "        OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "        if OPENAI_API_KEY:\n",
    "            openai_disponible = True\n",
    "            print(\"âœ… OpenAI API key cargada desde variable de entorno\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if not openai_disponible:\n",
    "    print(\"âš ï¸ OpenAI API key no encontrada\")\n",
    "    print(\"   Las secciones de OpenAI se saltarÃ¡n automÃ¡ticamente\")\n",
    "    print(\"   Para habilitarlas, agrega tu key en Colab Secrets con nombre OPENAI_API_KEY\")\n",
    "\n",
    "# Configurar cliente OpenAI si estÃ¡ disponible\n",
    "if openai_disponible:\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0297fb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. MÃ³dulo de recopilaciÃ³n de datos\n",
    "\n",
    "### 2.1 API de Clima: Open-Meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_clima(ciudad: str, lat: float, lon: float, dias: int = 7) -> dict:\n",
    "    \"\"\"Obtiene clima actual y pronÃ³stico de Open-Meteo.\"\"\"\n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": lat, \"longitude\": lon,\n",
    "        \"current\": \"temperature_2m,relative_humidity_2m,wind_speed_10m,apparent_temperature,weather_code\",\n",
    "        \"daily\": \"temperature_2m_max,temperature_2m_min,precipitation_sum,wind_speed_10m_max\",\n",
    "        \"timezone\": \"America/Mazatlan\", \"forecast_days\": dias,\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(url, params=params, timeout=10)\n",
    "        datos = resp.json()\n",
    "        return {\"ciudad\": ciudad, \"actual\": datos.get(\"current\", {}),\n",
    "                \"diario\": datos.get(\"daily\", {}), \"status\": \"ok\"}\n",
    "    except Exception as e:\n",
    "        return {\"ciudad\": ciudad, \"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "# Probar\n",
    "ciudades_sinaloa = {\n",
    "    \"CuliacÃ¡n\": (24.8049, -107.3940), \"MazatlÃ¡n\": (23.2494, -106.4111),\n",
    "    \"Los Mochis\": (25.7908, -108.9939), \"Guasave\": (25.5667, -108.4667),\n",
    "}\n",
    "\n",
    "datos_clima = {}\n",
    "for ciudad, (lat, lon) in ciudades_sinaloa.items():\n",
    "    datos_clima[ciudad] = obtener_clima(ciudad, lat, lon)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "for ciudad, datos in datos_clima.items():\n",
    "    if datos[\"status\"] == \"ok\":\n",
    "        actual = datos[\"actual\"]\n",
    "        print(f\"ğŸŒ¡ï¸ {ciudad}: {actual.get('temperature_2m', 'N/A')}Â°C, \"\n",
    "              f\"Humedad: {actual.get('relative_humidity_2m', 'N/A')}%, \"\n",
    "              f\"Viento: {actual.get('wind_speed_10m', 'N/A')} km/h\")\n",
    "    else:\n",
    "        print(f\"âŒ {ciudad}: {datos.get('error', 'Error desconocido')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44508d48",
   "metadata": {},
   "source": [
    "### 2.2 API de Tipo de Cambio: ExchangeRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_tipo_cambio(base: str = \"MXN\") -> dict:\n",
    "    \"\"\"Obtiene tipos de cambio actualizados.\"\"\"\n",
    "    url = f\"https://open.er-api.com/v6/latest/{base}\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10)\n",
    "        datos = resp.json()\n",
    "        if datos.get(\"result\") == \"success\":\n",
    "            return {\"status\": \"ok\", \"base\": base, \"rates\": datos[\"rates\"],\n",
    "                    \"updated\": datos.get(\"time_last_update_utc\", \"\")}\n",
    "        return {\"status\": \"error\", \"error\": \"API returned non-success\"}\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "tc = obtener_tipo_cambio(\"MXN\")\n",
    "if tc[\"status\"] == \"ok\":\n",
    "    monedas = {\"USD\": \"DÃ³lar\", \"EUR\": \"Euro\", \"GBP\": \"Libra\", \"CAD\": \"DÃ³lar canadiense\",\n",
    "               \"JPY\": \"Yen\", \"BRL\": \"Real\", \"COP\": \"Peso colombiano\"}\n",
    "    print(f\"ğŸ’± Tipo de cambio ({tc['base']}):\")\n",
    "    for codigo, nombre in monedas.items():\n",
    "        tasa = tc[\"rates\"].get(codigo, 0)\n",
    "        inverso = 1 / tasa if tasa else 0\n",
    "        print(f\"  1 {codigo} ({nombre:<20}) = ${inverso:.2f} MXN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882ab7b",
   "metadata": {},
   "source": [
    "### 2.3 API de PaÃ­ses: RestCountries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_datos_pais(nombre: str) -> dict:\n",
    "    \"\"\"Obtiene datos de un paÃ­s desde RestCountries.\"\"\"\n",
    "    url = f\"https://restcountries.com/v3.1/name/{nombre}\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10)\n",
    "        if resp.status_code == 200:\n",
    "            datos = resp.json()[0]\n",
    "            moneda = list(datos.get(\"currencies\", {}).values())\n",
    "            return {\n",
    "                \"status\": \"ok\", \"nombre\": datos[\"name\"][\"common\"],\n",
    "                \"nombre_oficial\": datos[\"name\"].get(\"official\", \"\"),\n",
    "                \"capital\": datos.get(\"capital\", [\"N/A\"])[0],\n",
    "                \"region\": datos.get(\"region\", \"\"),\n",
    "                \"subregion\": datos.get(\"subregion\", \"\"),\n",
    "                \"poblacion\": datos.get(\"population\", 0),\n",
    "                \"area_km2\": datos.get(\"area\", 0),\n",
    "                \"moneda\": moneda[0][\"name\"] if moneda else \"N/A\",\n",
    "                \"idiomas\": list(datos.get(\"languages\", {}).values()),\n",
    "                \"bandera\": datos.get(\"flag\", \"\"),\n",
    "            }\n",
    "        return {\"status\": \"error\", \"error\": f\"HTTP {resp.status_code}\"}\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "paises = [\"Mexico\", \"Brazil\", \"Chile\", \"Argentina\", \"Colombia\"]\n",
    "datos_paises = []\n",
    "for pais in paises:\n",
    "    datos = obtener_datos_pais(pais)\n",
    "    if datos[\"status\"] == \"ok\":\n",
    "        datos_paises.append(datos)\n",
    "        print(f\"{datos['bandera']} {datos['nombre']}: {datos['poblacion']:,} hab, Capital: {datos['capital']}\")\n",
    "    time.sleep(0.3)\n",
    "\n",
    "df_paises = pd.DataFrame(datos_paises)\n",
    "df_paises[[\"nombre\", \"capital\", \"poblacion\", \"area_km2\", \"moneda\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b9e01f",
   "metadata": {},
   "source": [
    "### 2.4 API de OpenAI: GeneraciÃ³n de texto con GPT\n",
    "\n",
    "Esta es la API que le da \"inteligencia\" a nuestro asistente. GPT puede analizar datos y generar reportes en lenguaje natural.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_texto(prompt: str, system: str = \"Eres un analista de datos experto. Respondes en espaÃ±ol, de forma concisa y profesional.\", max_tokens: int = 500) -> str:\n",
    "    \"\"\"Genera texto usando la API de OpenAI.\"\"\"\n",
    "    if not openai_disponible:\n",
    "        return \"[OpenAI no disponible â€” configura tu API key para habilitar esta funciÃ³n]\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_tokens=max_tokens, temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"[Error al llamar OpenAI: {e}]\"\n",
    "\n",
    "respuesta = generar_texto(\"En una oraciÃ³n, Â¿quÃ© es Machine Learning?\")\n",
    "print(f\"ğŸ¤– GPT dice: {respuesta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612741f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. AnÃ¡lisis de datos combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03661f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir DataFrame de clima\n",
    "registros_clima = []\n",
    "for ciudad, datos in datos_clima.items():\n",
    "    if datos[\"status\"] == \"ok\":\n",
    "        actual = datos[\"actual\"]\n",
    "        diario = datos[\"diario\"]\n",
    "        registro = {\n",
    "            \"ciudad\": ciudad, \"temp_actual\": actual.get(\"temperature_2m\"),\n",
    "            \"sensacion\": actual.get(\"apparent_temperature\"),\n",
    "            \"humedad\": actual.get(\"relative_humidity_2m\"),\n",
    "            \"viento\": actual.get(\"wind_speed_10m\"),\n",
    "        }\n",
    "        if diario:\n",
    "            temps_max = [t for t in diario.get(\"temperature_2m_max\", []) if t is not None]\n",
    "            temps_min = [t for t in diario.get(\"temperature_2m_min\", []) if t is not None]\n",
    "            lluvias = [p for p in diario.get(\"precipitation_sum\", []) if p is not None]\n",
    "            if temps_max:\n",
    "                registro[\"temp_max_prom\"] = np.mean(temps_max)\n",
    "                registro[\"temp_min_prom\"] = np.mean(temps_min)\n",
    "                registro[\"lluvia_total_7d\"] = sum(lluvias)\n",
    "                registro[\"dias_lluvia\"] = sum(1 for p in lluvias if p > 0)\n",
    "        registros_clima.append(registro)\n",
    "\n",
    "df_clima = pd.DataFrame(registros_clima)\n",
    "print(\"ğŸ“Š Datos de clima consolidados:\")\n",
    "df_clima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VisualizaciÃ³n de clima\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "colores = [\"#2E86AB\", \"#F18F01\", \"#A23B72\", \"#C73E1D\"]\n",
    "\n",
    "ax = axes[0, 0]\n",
    "if not df_clima.empty:\n",
    "    bars = ax.bar(df_clima[\"ciudad\"], df_clima[\"temp_actual\"], color=colores[:len(df_clima)])\n",
    "    for bar, temp in zip(bars, df_clima[\"temp_actual\"]):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
    "                f\"{temp:.1f}Â°C\", ha=\"center\", fontweight=\"bold\")\n",
    "ax.set_title(\"ğŸŒ¡ï¸ Temperatura Actual\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Â°C\")\n",
    "\n",
    "ax = axes[0, 1]\n",
    "if not df_clima.empty:\n",
    "    bars = ax.bar(df_clima[\"ciudad\"], df_clima[\"humedad\"], color=colores[:len(df_clima)])\n",
    "    for bar, hum in zip(bars, df_clima[\"humedad\"]):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                f\"{hum:.0f}%\", ha=\"center\", fontweight=\"bold\")\n",
    "ax.set_title(\"ğŸ’§ Humedad\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"%\")\n",
    "\n",
    "ax = axes[1, 0]\n",
    "if \"temp_max_prom\" in df_clima.columns:\n",
    "    x = range(len(df_clima))\n",
    "    ax.bar(x, df_clima[\"temp_max_prom\"] - df_clima[\"temp_min_prom\"],\n",
    "           bottom=df_clima[\"temp_min_prom\"], color=colores[:len(df_clima)], alpha=0.7)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df_clima[\"ciudad\"])\n",
    "ax.set_title(\"ğŸŒ¤ï¸ Rango Temperatura (7 dÃ­as)\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Â°C\")\n",
    "\n",
    "ax = axes[1, 1]\n",
    "if \"lluvia_total_7d\" in df_clima.columns:\n",
    "    bars = ax.bar(df_clima[\"ciudad\"], df_clima[\"lluvia_total_7d\"], color=colores[:len(df_clima)])\n",
    "    for bar, lluvia in zip(bars, df_clima[\"lluvia_total_7d\"]):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                f\"{lluvia:.1f}mm\", ha=\"center\", fontweight=\"bold\")\n",
    "ax.set_title(\"ğŸŒ§ï¸ Lluvia Total (7 dÃ­as)\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"mm\")\n",
    "\n",
    "for a in axes.flat:\n",
    "    a.spines[\"top\"].set_visible(False)\n",
    "    a.spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"Dashboard ClimÃ¡tico â€” Sinaloa en Tiempo Real\", fontsize=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09af226",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. PredicciÃ³n con Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a949c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "gapminder = px.data.gapminder()\n",
    "gm = gapminder.copy()\n",
    "gm[\"log_pib\"] = np.log10(gm[\"gdpPercap\"])\n",
    "gm[\"log_pop\"] = np.log10(gm[\"pop\"])\n",
    "continentes_dummies = pd.get_dummies(gm[\"continent\"], prefix=\"cont\", drop_first=True)\n",
    "gm = pd.concat([gm, continentes_dummies], axis=1)\n",
    "\n",
    "feature_cols = [\"log_pib\", \"log_pop\", \"year\"] + list(continentes_dummies.columns)\n",
    "X = gm[feature_cols].values\n",
    "y = gm[\"lifeExp\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "modelo = GradientBoostingRegressor(n_estimators=200, max_depth=4, random_state=42)\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"ğŸ¤– Modelo entrenado: Gradient Boosting\")\n",
    "print(f\"   RÂ²:  {r2:.3f}\")\n",
    "print(f\"   MAE: {mae:.2f} aÃ±os\")\n",
    "\n",
    "importancias = pd.Series(modelo.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "print(f\"\\nğŸ“Š Top features:\")\n",
    "for feat, imp in importancias.head(5).items():\n",
    "    print(f\"   {feat}: {imp:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab378b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_esperanza_vida(pib_per_capita, poblacion, anio=2025, continente=\"Americas\"):\n",
    "    \"\"\"Predice esperanza de vida usando el modelo entrenado.\"\"\"\n",
    "    log_pib = np.log10(pib_per_capita)\n",
    "    log_pop = np.log10(poblacion)\n",
    "    features = {\"log_pib\": log_pib, \"log_pop\": log_pop, \"year\": anio}\n",
    "    for col in feature_cols:\n",
    "        if col.startswith(\"cont_\"):\n",
    "            features[col] = 1 if col == f\"cont_{continente}\" else 0\n",
    "    X_pred = np.array([[features[col] for col in feature_cols]])\n",
    "    return modelo.predict(X_pred)[0]\n",
    "\n",
    "paises_prediccion = {\n",
    "    \"MÃ©xico\": {\"pib\": 10_000, \"pop\": 130_000_000, \"cont\": \"Americas\"},\n",
    "    \"Brasil\": {\"pib\": 9_000, \"pop\": 215_000_000, \"cont\": \"Americas\"},\n",
    "    \"Chile\": {\"pib\": 17_000, \"pop\": 19_500_000, \"cont\": \"Americas\"},\n",
    "    \"Argentina\": {\"pib\": 10_000, \"pop\": 46_000_000, \"cont\": \"Americas\"},\n",
    "    \"Colombia\": {\"pib\": 6_500, \"pop\": 52_000_000, \"cont\": \"Americas\"},\n",
    "    \"JapÃ³n\": {\"pib\": 40_000, \"pop\": 125_000_000, \"cont\": \"Asia\"},\n",
    "    \"Nigeria\": {\"pib\": 2_200, \"pop\": 220_000_000, \"cont\": \"Africa\"},\n",
    "    \"Alemania\": {\"pib\": 48_000, \"pop\": 84_000_000, \"cont\": \"Europe\"},\n",
    "}\n",
    "\n",
    "print(\"ğŸ”® Predicciones de Esperanza de Vida (2025):\")\n",
    "print(f\"{'PaÃ­s':<15} {'PIB/cÃ¡p':>10} {'PoblaciÃ³n':>14} {'PredicciÃ³n':>12}\")\n",
    "print(\"-\" * 55)\n",
    "predicciones = {}\n",
    "for pais, datos in paises_prediccion.items():\n",
    "    pred = predecir_esperanza_vida(datos[\"pib\"], datos[\"pop\"], 2025, datos[\"cont\"])\n",
    "    predicciones[pais] = pred\n",
    "    print(f\"{pais:<15} ${datos['pib']:>9,} {datos['pop']:>13,} {pred:>10.1f} aÃ±os\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d917a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. AnÃ¡lisis What-If: Â¿QuÃ© pasarÃ­a si...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b19ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pib_base = 10_000\n",
    "poblacion_mx = 130_000_000\n",
    "escenarios_pib = np.arange(3000, 50001, 1000)\n",
    "predicciones_escenario = [predecir_esperanza_vida(pib, poblacion_mx, 2025, \"Americas\") for pib in escenarios_pib]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(escenarios_pib, predicciones_escenario, color=\"#2E86AB\", linewidth=2.5)\n",
    "ax.fill_between(escenarios_pib, predicciones_escenario, alpha=0.1, color=\"#2E86AB\")\n",
    "\n",
    "ev_actual = predecir_esperanza_vida(pib_base, poblacion_mx, 2025, \"Americas\")\n",
    "ax.axvline(pib_base, color=\"#C73E1D\", linestyle=\"--\", linewidth=2, alpha=0.7)\n",
    "ax.annotate(f\"MÃ©xico actual\\n${pib_base:,}\\n{ev_actual:.1f} aÃ±os\",\n",
    "            xy=(pib_base, ev_actual), xytext=(pib_base + 5000, ev_actual - 3),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"#C73E1D\"),\n",
    "            fontsize=10, color=\"#C73E1D\", fontweight=\"bold\")\n",
    "\n",
    "ev_doble = predecir_esperanza_vida(pib_base * 2, poblacion_mx, 2025, \"Americas\")\n",
    "ax.axvline(pib_base * 2, color=\"#27AE60\", linestyle=\"--\", linewidth=2, alpha=0.7)\n",
    "ax.annotate(f\"PIB Ã—2\\n${pib_base*2:,}\\n{ev_doble:.1f} aÃ±os\",\n",
    "            xy=(pib_base * 2, ev_doble), xytext=(pib_base * 2 + 3000, ev_doble + 2),\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"#27AE60\"),\n",
    "            fontsize=10, color=\"#27AE60\", fontweight=\"bold\")\n",
    "\n",
    "ax.set_title(\"ğŸ‡²ğŸ‡½ Â¿CÃ³mo afecta el PIB a la esperanza de vida de MÃ©xico?\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"PIB per cÃ¡pita (USD)\")\n",
    "ax.set_ylabel(\"Esperanza de vida predicha (aÃ±os)\")\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f\"${x:,.0f}\"))\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "ganancia = ev_doble - ev_actual\n",
    "print(f\"\\nğŸ“Š Si MÃ©xico duplicara su PIB per cÃ¡pita:\")\n",
    "print(f\"   Esperanza de vida pasarÃ­a de {ev_actual:.1f} a {ev_doble:.1f} aÃ±os (+{ganancia:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aeee8b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. GeneraciÃ³n de reportes con IA (OpenAI)\n",
    "\n",
    "AquÃ­ es donde la IA generativa hace su magia: toma todos los datos que recopilamos y genera un reporte en lenguaje natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4172180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar contexto con datos recopilados\n",
    "contexto_datos = f'''\n",
    "DATOS RECOPILADOS EN TIEMPO REAL:\n",
    "\n",
    "1. CLIMA EN SINALOA:\n",
    "{df_clima.to_string() if not df_clima.empty else 'No disponible'}\n",
    "\n",
    "2. TIPO DE CAMBIO:\n",
    "- 1 USD = ${1/tc[\"rates\"][\"USD\"]:.2f} MXN\n",
    "- 1 EUR = ${1/tc[\"rates\"][\"EUR\"]:.2f} MXN\n",
    "\n",
    "3. PREDICCIONES DE ESPERANZA DE VIDA (modelo ML con RÂ²={r2:.3f}):\n",
    "{json.dumps(predicciones, indent=2, ensure_ascii=False)}\n",
    "\n",
    "4. ANÃLISIS WHAT-IF:\n",
    "- MÃ©xico actual: PIB $10,000 â†’ {ev_actual:.1f} aÃ±os de esperanza de vida\n",
    "- Si duplica PIB: $20,000 â†’ {ev_doble:.1f} aÃ±os (+{ganancia:.1f} aÃ±os)\n",
    "'''\n",
    "\n",
    "prompt_reporte = f'''BasÃ¡ndote en los siguientes datos reales recopilados hoy, genera un reporte ejecutivo breve (mÃ¡ximo 300 palabras) con:\n",
    "1. Resumen del clima en Sinaloa\n",
    "2. SituaciÃ³n del tipo de cambio\n",
    "3. Insight sobre esperanza de vida en LATAM\n",
    "4. RecomendaciÃ³n basada en el anÃ¡lisis what-if de MÃ©xico\n",
    "\n",
    "{contexto_datos}\n",
    "\n",
    "Formato: usa bullets y sÃ© directo. Incluye nÃºmeros especÃ­ficos.\n",
    "'''\n",
    "\n",
    "print(\"ğŸ“ Generando reporte con IA...\")\n",
    "reporte = generar_texto(prompt_reporte, max_tokens=800)\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"  REPORTE EJECUTIVO â€” INTELIGENCIA DE NEGOCIOS\")\n",
    "print(\"  Generado con Python + APIs + ML + GPT\")\n",
    "print(f\"  {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"=\" * 65)\n",
    "print(reporte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea53925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asistente que responde preguntas sobre los datos\n",
    "def preguntar_al_asistente(pregunta: str) -> str:\n",
    "    \"\"\"Hace una pregunta al asistente de BI.\"\"\"\n",
    "    system = \"Eres un asistente de Inteligencia de Negocios para Ver de Verdad, una cadena de Ã³pticas en Sinaloa, MÃ©xico. Respondes en espaÃ±ol con datos especÃ­ficos.\"\n",
    "    prompt = f\"Datos disponibles:\\n{contexto_datos}\\n\\nPregunta: {pregunta}\"\n",
    "    return generar_texto(prompt, system=system, max_tokens=300)\n",
    "\n",
    "preguntas = [\n",
    "    \"Â¿Es buen momento para importar armazones de Europa considerando el tipo de cambio?\",\n",
    "    \"Â¿CÃ³mo estÃ¡ el clima para abrir una nueva sucursal en MazatlÃ¡n esta semana?\",\n",
    "    \"Â¿QuÃ© paÃ­s de LATAM tiene mejor pronÃ³stico de esperanza de vida y por quÃ©?\",\n",
    "]\n",
    "\n",
    "for pregunta in preguntas:\n",
    "    print(f\"\\nâ“ {pregunta}\")\n",
    "    respuesta = preguntar_al_asistente(pregunta)\n",
    "    print(f\"ğŸ¤– {respuesta}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e36f17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Dashboard final integrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8eeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 14))\n",
    "fig.patch.set_facecolor(\"#FAFAFA\")\n",
    "fig.suptitle(\"DASHBOARD DE INTELIGENCIA DE NEGOCIOS\\nVer de Verdad â€” Datos en Tiempo Real\",\n",
    "             fontsize=20, fontweight=\"bold\", y=0.99)\n",
    "\n",
    "# KPIs\n",
    "ax_kpi = fig.add_axes([0.05, 0.94, 0.9, 0.03])\n",
    "ax_kpi.axis(\"off\")\n",
    "usd_mxn = 1 / tc[\"rates\"][\"USD\"] if tc[\"status\"] == \"ok\" else 0\n",
    "temp_cln = df_clima[df_clima[\"ciudad\"] == \"CuliacÃ¡n\"][\"temp_actual\"].values[0] if not df_clima.empty else 0\n",
    "kpi_text = (f\"ğŸ’µ USD/MXN: ${usd_mxn:.2f}    |    ğŸŒ¡ï¸ CuliacÃ¡n: {temp_cln:.1f}Â°C    |    \"\n",
    "            f\"ğŸ¤– Modelo ML: RÂ²={r2:.3f}    |    ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "ax_kpi.text(0.5, 0.5, kpi_text, ha=\"center\", va=\"center\", fontsize=12)\n",
    "\n",
    "# 1. Clima\n",
    "ax1 = fig.add_subplot(2, 3, 1)\n",
    "colores_c = [\"#2E86AB\", \"#F18F01\", \"#A23B72\", \"#C73E1D\"]\n",
    "if not df_clima.empty:\n",
    "    bars = ax1.bar(df_clima[\"ciudad\"], df_clima[\"temp_actual\"], color=colores_c[:len(df_clima)])\n",
    "    for bar, temp in zip(bars, df_clima[\"temp_actual\"]):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
    "                f\"{temp:.1f}Â°\", ha=\"center\", fontweight=\"bold\", fontsize=9)\n",
    "ax1.set_title(\"ğŸŒ¡ï¸ Temperatura\", fontweight=\"bold\")\n",
    "ax1.spines[\"top\"].set_visible(False)\n",
    "ax1.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# 2. Tipo de cambio\n",
    "ax2 = fig.add_subplot(2, 3, 2)\n",
    "mons = [\"USD\", \"EUR\", \"GBP\", \"CAD\"]\n",
    "vals = [1/tc[\"rates\"][m] for m in mons]\n",
    "bars = ax2.bar(mons, vals, color=colores_c)\n",
    "for bar, val in zip(bars, vals):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "            f\"${val:.2f}\", ha=\"center\", fontweight=\"bold\", fontsize=9)\n",
    "ax2.set_title(\"ğŸ’± Tipo de Cambio (â†’ MXN)\", fontweight=\"bold\")\n",
    "ax2.spines[\"top\"].set_visible(False)\n",
    "ax2.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# 3. Predicciones de esperanza de vida\n",
    "ax3 = fig.add_subplot(2, 3, 3)\n",
    "paises_ev = list(predicciones.keys())\n",
    "valores_ev = list(predicciones.values())\n",
    "orden = np.argsort(valores_ev)\n",
    "colores_ev = [\"#2E86AB\" if p == \"MÃ©xico\" else \"#A4C3D2\" for p in np.array(paises_ev)[orden]]\n",
    "ax3.barh(np.array(paises_ev)[orden], np.array(valores_ev)[orden], color=colores_ev)\n",
    "for i, (p, v) in enumerate(zip(np.array(paises_ev)[orden], np.array(valores_ev)[orden])):\n",
    "    ax3.text(v + 0.2, i, f\"{v:.1f}\", va=\"center\", fontsize=9)\n",
    "ax3.set_title(\"ğŸ”® Esperanza de Vida (ML)\", fontweight=\"bold\")\n",
    "ax3.spines[\"top\"].set_visible(False)\n",
    "ax3.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# 4. What-If MÃ©xico\n",
    "ax4 = fig.add_subplot(2, 3, 4)\n",
    "ax4.plot(escenarios_pib, predicciones_escenario, color=\"#2E86AB\", linewidth=2)\n",
    "ax4.axvline(pib_base, color=\"#C73E1D\", linestyle=\"--\", alpha=0.7, label=\"Actual\")\n",
    "ax4.axvline(pib_base * 2, color=\"#27AE60\", linestyle=\"--\", alpha=0.7, label=\"PIB Ã—2\")\n",
    "ax4.fill_between(escenarios_pib, predicciones_escenario, alpha=0.1, color=\"#2E86AB\")\n",
    "ax4.set_title(\"ğŸ“ˆ What-If: PIB vs Esperanza (MX)\", fontweight=\"bold\")\n",
    "ax4.legend(fontsize=8)\n",
    "ax4.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f\"${x/1000:.0f}K\"))\n",
    "ax4.spines[\"top\"].set_visible(False)\n",
    "ax4.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# 5. Importancia de features\n",
    "ax5 = fig.add_subplot(2, 3, 5)\n",
    "top_imp = importancias.head(6).sort_values()\n",
    "ax5.barh(top_imp.index, top_imp.values, color=\"#A23B72\")\n",
    "ax5.set_title(\"ğŸ¯ Features ML\", fontweight=\"bold\")\n",
    "ax5.spines[\"top\"].set_visible(False)\n",
    "ax5.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# 6. Info\n",
    "ax6 = fig.add_subplot(2, 3, 6)\n",
    "ax6.axis(\"off\")\n",
    "info = [\"ğŸ“Š FUENTES DE DATOS\", \"\", \"ğŸŒ¡ï¸ Open-Meteo (clima)\", \"ğŸ’± ExchangeRate (TC)\",\n",
    "        \"ğŸŒ RestCountries (paÃ­ses)\", f\"ğŸ¤– Scikit-learn (RÂ²={r2:.3f})\",\n",
    "        \"ğŸ§  OpenAI GPT (reportes)\", \"\", \"Culiacan.AI\"]\n",
    "ax6.text(0.05, 0.95, \"\\n\".join(info), transform=ax6.transAxes, fontsize=10,\n",
    "         verticalalignment=\"top\", fontfamily=\"monospace\",\n",
    "         bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.01, 1, 0.93])\n",
    "fig.savefig(\"datos/dashboard_bi.png\", dpi=200, bbox_inches=\"tight\", facecolor=\"#FAFAFA\")\n",
    "print(\"âœ… Dashboard guardado como datos/dashboard_bi.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596afd18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”¥ Retos\n",
    "\n",
    "1. **Agregar mÃ¡s APIs:** Integra una API de noticias (como NewsAPI) o la API de Wikipedia para agregar contexto a tu reporte. Haz que GPT integre las noticias relevantes al anÃ¡lisis.\n",
    "\n",
    "2. **Sistema de alertas:** Crea un sistema que revise el clima y tipo de cambio cada cierto tiempo (simula con un loop) y envÃ­e alertas cuando la temperatura supere 40Â°C o el dÃ³lar suba mÃ¡s de un 2%.\n",
    "\n",
    "3. **Asistente conversacional:** Construye un loop interactivo donde el usuario pueda hacer preguntas en lenguaje natural y el asistente responda usando los datos recopilados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9bc51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reto 1: Agregar mÃ¡s APIs\n",
    "# Tu cÃ³digo aquÃ­ ğŸ‘‡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reto 2: Sistema de alertas\n",
    "# Tu cÃ³digo aquÃ­ ğŸ‘‡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reto 3: Asistente conversacional\n",
    "# Tu cÃ³digo aquÃ­ ğŸ‘‡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc62d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ Resumen: lo que construimos\n",
    "\n",
    "### Arquitectura del sistema\n",
    "\n",
    "```\n",
    "         APIs externas                    ML + IA\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚ Open-Meteo (clima)   â”‚      â”‚ Scikit-learn (ML) â”‚\n",
    "  â”‚ ExchangeRate (TC)    â”‚â”€â”€â”€â”€â”€â–¶â”‚ OpenAI GPT (NLP)  â”‚\n",
    "  â”‚ RestCountries (datos)â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "             â”‚                           â–¼\n",
    "             â–¼                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   Dashboard +     â”‚\n",
    "  â”‚  Pandas + NumPy      â”‚â”€â”€â”€â”€â”€â–¶â”‚   Reporte IA      â”‚\n",
    "  â”‚  (anÃ¡lisis)          â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### TecnologÃ­as usadas en el proyecto\n",
    "\n",
    "| TecnologÃ­a | Notebook donde la aprendimos |\n",
    "|-----------|----------------------------|\n",
    "| Pandas | 07 â€” Pandas BÃ¡sico |\n",
    "| Matplotlib | 08 â€” VisualizaciÃ³n |\n",
    "| APIs + JSON | 10 â€” APIs y JSON |\n",
    "| NumPy | 11 â€” Intro a NumPy |\n",
    "| AnÃ¡lisis de datos | 12 â€” AnÃ¡lisis de Datos Real |\n",
    "| Machine Learning | 13 â€” Intro a Machine Learning |\n",
    "| OpenAI API | 14 â€” Este notebook |\n",
    "\n",
    "---\n",
    "\n",
    "## â­ï¸ Â¿QuÃ© sigue?\n",
    "\n",
    "En el Ãºltimo notebook del curso obtendrÃ¡s tu guÃ­a de **PrÃ³ximos Pasos** en tu camino con Python e IA.\n",
    "\n",
    "ğŸ‘‰ [15 â€” PrÃ³ximos Pasos](15_Proximos_Pasos.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "<p align=\"center\">\n",
    "  Hecho con â¤ï¸ por <a href=\"https://culiacan.ai\">Culiacan.AI</a> â€” CuliacÃ¡n reconocida en el mundo por su talento y emprendimiento en Inteligencia Artificial\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
